{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Exploratory Data Analysis - Nepal Earthquake Building Damage Data\n",
        "\n",
        "This notebook performs an exploratory data analysis on the Nepal earthquake building damage dataset. The main objective is to predict `damage_grade` based on building characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', 50)\n",
        "\n",
        "# Set plotting style (try different style options for compatibility)\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "except:\n",
        "    try:\n",
        "        plt.style.use('seaborn')\n",
        "    except:\n",
        "        plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load the Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('nepal_dat.csv')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Number of rows: {df.shape[0]:,}\")\n",
        "print(f\"Number of columns: {df.shape[1]}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Types and Variable Classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get data types\n",
        "print(\"Data Types Summary:\")\n",
        "print(\"=\" * 60)\n",
        "print(df.dtypes.value_counts())\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# Create a summary dataframe\n",
        "data_types_summary = pd.DataFrame({\n",
        "    'Column': df.columns,\n",
        "    'Data_Type': df.dtypes,\n",
        "    'Is_Numeric': df.dtypes.apply(lambda x: pd.api.types.is_numeric_dtype(x)),\n",
        "    'Is_String': df.dtypes.apply(lambda x: pd.api.types.is_string_dtype(x) or pd.api.types.is_object_dtype(x))\n",
        "})\n",
        "\n",
        "# Classify variables\n",
        "data_types_summary['Variable_Type'] = data_types_summary.apply(\n",
        "    lambda row: 'Numeric' if row['Is_Numeric'] else 'String/Categorical',\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"\\nDetailed Data Types by Column:\")\n",
        "print(\"=\" * 80)\n",
        "print(data_types_summary.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary counts\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Variable Type Summary:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total Numeric Variables: {data_types_summary['Is_Numeric'].sum()}\")\n",
        "print(f\"Total String/Categorical Variables: {data_types_summary['Is_String'].sum()}\")\n",
        "print(\"\\nNumeric Variables:\")\n",
        "numeric_cols = data_types_summary[data_types_summary['Is_Numeric']]['Column'].tolist()\n",
        "print(numeric_cols)\n",
        "print(\"\\nString/Categorical Variables:\")\n",
        "string_cols = data_types_summary[data_types_summary['Is_String']]['Column'].tolist()\n",
        "print(string_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Missing Values (NA Count) per Column\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate missing values\n",
        "missing_data = pd.DataFrame({\n",
        "    'Column': df.columns,\n",
        "    'NA_Count': df.isna().sum(),\n",
        "    'NA_Percentage': (df.isna().sum() / len(df)) * 100\n",
        "})\n",
        "\n",
        "# Sort by NA count (descending)\n",
        "missing_data = missing_data.sort_values('NA_Count', ascending=False)\n",
        "\n",
        "print(\"Missing Values Summary:\")\n",
        "print(\"=\" * 80)\n",
        "print(missing_data.to_string(index=False))\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Missing Values Summary Statistics:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total columns with missing values: {(missing_data['NA_Count'] > 0).sum()}\")\n",
        "print(f\"Total missing values in dataset: {missing_data['NA_Count'].sum():,}\")\n",
        "print(f\"Percentage of dataset that is missing: {(missing_data['NA_Count'].sum() / (df.shape[0] * df.shape[1])) * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize missing values\n",
        "if missing_data['NA_Count'].sum() > 0:\n",
        "    # Filter to only columns with missing values\n",
        "    missing_with_na = missing_data[missing_data['NA_Count'] > 0]\n",
        "    \n",
        "    if len(missing_with_na) > 0:\n",
        "        plt.figure(figsize=(12, max(6, len(missing_with_na) * 0.3)))\n",
        "        plt.barh(missing_with_na['Column'], missing_with_na['NA_Count'])\n",
        "        plt.xlabel('Number of Missing Values')\n",
        "        plt.title('Missing Values by Column')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"No missing values found in the dataset!\")\n",
        "else:\n",
        "    print(\"No missing values found in the dataset!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Target Variable Analysis: damage_grade\n",
        "\n",
        "Since `damage_grade` is the prediction objective, let's examine it in detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if damage_grade exists\n",
        "if 'damage_grade' in df.columns:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"DAMAGE_GRADE ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    print(f\"\\nData type: {df['damage_grade'].dtype}\")\n",
        "    print(f\"Missing values: {df['damage_grade'].isna().sum()}\")\n",
        "    print(f\"Unique values: {df['damage_grade'].nunique()}\")\n",
        "    print(f\"Unique value list: {sorted(df['damage_grade'].unique())}\")\n",
        "    \n",
        "    print(\"\\nValue Counts:\")\n",
        "    print(df['damage_grade'].value_counts().sort_index())\n",
        "    \n",
        "    print(\"\\nValue Counts (Percentages):\")\n",
        "    print((df['damage_grade'].value_counts(normalize=True).sort_index() * 100).round(2))\n",
        "    \n",
        "    print(\"\\nBasic Statistics:\")\n",
        "    print(df['damage_grade'].describe())\n",
        "else:\n",
        "    print(\"WARNING: 'damage_grade' column not found in the dataset!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize damage_grade distribution\n",
        "if 'damage_grade' in df.columns:\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "    \n",
        "    # Bar plot\n",
        "    damage_counts = df['damage_grade'].value_counts().sort_index()\n",
        "    axes[0].bar(damage_counts.index, damage_counts.values, color='steelblue', alpha=0.7)\n",
        "    axes[0].set_xlabel('Damage Grade')\n",
        "    axes[0].set_ylabel('Frequency')\n",
        "    axes[0].set_title('Distribution of Damage Grade (Count)')\n",
        "    axes[0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # Add count labels on bars\n",
        "    for i, v in enumerate(damage_counts.values):\n",
        "        axes[0].text(damage_counts.index[i], v, f'{v:,}', \n",
        "                    ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # Pie chart\n",
        "    damage_pct = df['damage_grade'].value_counts(normalize=True).sort_index() * 100\n",
        "    axes[1].pie(damage_pct.values, labels=[f'Grade {idx}' for idx in damage_pct.index], \n",
        "                autopct='%1.1f%%', startangle=90)\n",
        "    axes[1].set_title('Distribution of Damage Grade (Percentage)')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Numeric Variables Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics for numeric variables\n",
        "if len(numeric_cols) > 0:\n",
        "    print(\"Summary Statistics for Numeric Variables:\")\n",
        "    print(\"=\" * 100)\n",
        "    numeric_summary = df[numeric_cols].describe()\n",
        "    print(numeric_summary)\n",
        "    \n",
        "    # Additional statistics\n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"Additional Statistics:\")\n",
        "    print(\"=\" * 100)\n",
        "    additional_stats = pd.DataFrame({\n",
        "        'Column': numeric_cols,\n",
        "        'Min': [df[col].min() for col in numeric_cols],\n",
        "        'Max': [df[col].max() for col in numeric_cols],\n",
        "        'Mean': [df[col].mean() for col in numeric_cols],\n",
        "        'Median': [df[col].median() for col in numeric_cols],\n",
        "        'Std': [df[col].std() for col in numeric_cols],\n",
        "        'Skewness': [df[col].skew() for col in numeric_cols],\n",
        "        'Unique_Values': [df[col].nunique() for col in numeric_cols]\n",
        "    })\n",
        "    print(additional_stats.to_string(index=False))\n",
        "else:\n",
        "    print(\"No numeric variables found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Categorical/String Variables Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze categorical/string variables\n",
        "if len(string_cols) > 0:\n",
        "    print(\"Categorical/String Variables Analysis:\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    for col in string_cols:\n",
        "        print(f\"\\n{col}:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(f\"  Data type: {df[col].dtype}\")\n",
        "        print(f\"  Unique values: {df[col].nunique()}\")\n",
        "        print(f\"  Unique value list: {sorted(df[col].unique())}\")\n",
        "        print(f\"  Value counts:\")\n",
        "        value_counts = df[col].value_counts()\n",
        "        for val, count in value_counts.items():\n",
        "            pct = (count / len(df)) * 100\n",
        "            print(f\"    '{val}': {count:,} ({pct:.2f}%)\")\n",
        "else:\n",
        "    print(\"No categorical/string variables found!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Relationship Between Features and Target Variable\n",
        "\n",
        "Let's examine how different features relate to damage_grade.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation between numeric features and damage_grade\n",
        "if 'damage_grade' in df.columns and len(numeric_cols) > 0:\n",
        "    # Exclude damage_grade from numeric_cols for correlation\n",
        "    feature_numeric_cols = [col for col in numeric_cols if col != 'damage_grade']\n",
        "    \n",
        "    if len(feature_numeric_cols) > 0:\n",
        "        correlations = df[feature_numeric_cols + ['damage_grade']].corr()['damage_grade'].sort_values(ascending=False)\n",
        "        correlations = correlations.drop('damage_grade')  # Remove self-correlation\n",
        "        \n",
        "        print(\"Correlation with damage_grade (Numeric Features):\")\n",
        "        print(\"=\" * 80)\n",
        "        corr_df = pd.DataFrame({\n",
        "            'Feature': correlations.index,\n",
        "            'Correlation': correlations.values\n",
        "        })\n",
        "        print(corr_df.to_string(index=False))\n",
        "        \n",
        "        # Visualize correlations\n",
        "        plt.figure(figsize=(10, max(6, len(correlations) * 0.4)))\n",
        "        plt.barh(corr_df['Feature'], corr_df['Correlation'], color='coral', alpha=0.7)\n",
        "        plt.xlabel('Correlation with damage_grade')\n",
        "        plt.title('Feature Correlations with Target Variable (damage_grade)')\n",
        "        plt.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze categorical variables vs damage_grade\n",
        "if 'damage_grade' in df.columns and len(string_cols) > 0:\n",
        "    print(\"\\nCategorical Variables vs damage_grade:\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    # Show crosstab for each categorical variable\n",
        "    for col in string_cols[:10]:  # Limit to first 10 to avoid too much output\n",
        "        print(f\"\\n{col} vs damage_grade:\")\n",
        "        print(\"-\" * 80)\n",
        "        crosstab = pd.crosstab(df[col], df['damage_grade'], margins=True)\n",
        "        print(crosstab)\n",
        "        \n",
        "        # Percentage crosstab\n",
        "        print(f\"\\n{col} vs damage_grade (Percentages):\")\n",
        "        crosstab_pct = pd.crosstab(df[col], df['damage_grade'], normalize='index') * 100\n",
        "        print(crosstab_pct.round(2))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Key Insights Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive summary\n",
        "print(\"=\" * 100)\n",
        "print(\"EXPLORATORY DATA ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "print(f\"\\n1. Dataset Overview:\")\n",
        "print(f\"   - Total rows: {df.shape[0]:,}\")\n",
        "print(f\"   - Total columns: {df.shape[1]}\")\n",
        "print(f\"   - Numeric variables: {data_types_summary['Is_Numeric'].sum()}\")\n",
        "print(f\"   - String/Categorical variables: {data_types_summary['Is_String'].sum()}\")\n",
        "\n",
        "print(f\"\\n2. Missing Values:\")\n",
        "print(f\"   - Columns with missing values: {(missing_data['NA_Count'] > 0).sum()}\")\n",
        "print(f\"   - Total missing values: {missing_data['NA_Count'].sum():,}\")\n",
        "\n",
        "if 'damage_grade' in df.columns:\n",
        "    print(f\"\\n3. Target Variable (damage_grade):\")\n",
        "    print(f\"   - Data type: {df['damage_grade'].dtype}\")\n",
        "    print(f\"   - Unique values: {sorted(df['damage_grade'].unique())}\")\n",
        "    print(f\"   - Missing values: {df['damage_grade'].isna().sum()}\")\n",
        "    print(f\"   - Distribution:\")\n",
        "    for grade, count in df['damage_grade'].value_counts().sort_index().items():\n",
        "        pct = (count / len(df)) * 100\n",
        "        print(f\"     Grade {grade}: {count:,} ({pct:.2f}%)\")\n",
        "\n",
        "print(f\"\\n4. Data Quality:\")\n",
        "print(f\"   - No missing values: {(missing_data['NA_Count'] == 0).sum()} columns\")\n",
        "print(f\"   - Complete cases: {df.dropna().shape[0]:,} rows ({df.dropna().shape[0]/df.shape[0]*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
